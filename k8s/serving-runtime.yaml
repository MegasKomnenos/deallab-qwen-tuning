apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime 
metadata:
  name: kserve-vllm-custom
  namespace: kubeflow-user-example-com 
spec:
  supportedModelFormats:
    - name: vllm
      autoSelect: true
  containers:
    - name: kserve-container
      image: vllm/vllm-openai:v0.8.5
      command: ["python3", "-m", "vllm.entrypoints.openai.api_server"]
      env:
        - name: PORT
          value: "8080"
      resources:
        requests:
          cpu: "2"
          memory: "8Gi"
          nvidia.com/gpu: "1"
        limits:
          cpu: "4"
          memory: "16Gi"
          nvidia.com/gpu: "1"
